{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Pregnancies",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Glucose",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BloodPressure",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SkinThickness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Insulin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BMI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DiabetesPedigreeFunction",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Outcome",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "30df863d-ada6-44c0-b8b7-2b35d50ea739",
       "rows": [
        [
         "count",
         "768.0",
         "768.0",
         "768.0",
         "768.0",
         "768.0",
         "768.0",
         "768.0",
         "768.0",
         "768.0"
        ],
        [
         "mean",
         "3.8450520833333335",
         "120.89453125",
         "69.10546875",
         "20.536458333333332",
         "79.79947916666667",
         "31.992578124999998",
         "0.47187630208333325",
         "33.240885416666664",
         "0.3489583333333333"
        ],
        [
         "std",
         "3.3695780626988694",
         "31.97261819513622",
         "19.355807170644777",
         "15.952217567727637",
         "115.24400235133817",
         "7.884160320375446",
         "0.3313285950127749",
         "11.760231540678685",
         "0.47695137724279896"
        ],
        [
         "min",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.078",
         "21.0",
         "0.0"
        ],
        [
         "25%",
         "1.0",
         "99.0",
         "62.0",
         "0.0",
         "0.0",
         "27.3",
         "0.24375",
         "24.0",
         "0.0"
        ],
        [
         "50%",
         "3.0",
         "117.0",
         "72.0",
         "23.0",
         "30.5",
         "32.0",
         "0.3725",
         "29.0",
         "0.0"
        ],
        [
         "75%",
         "6.0",
         "140.25",
         "80.0",
         "32.0",
         "127.25",
         "36.6",
         "0.62625",
         "41.0",
         "1.0"
        ],
        [
         "max",
         "17.0",
         "199.0",
         "122.0",
         "99.0",
         "846.0",
         "67.1",
         "2.42",
         "81.0",
         "1.0"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6912"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.info(),\n",
    "        data.describe(),\n",
    "        data.size,\n",
    "        data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAN\n",
      "Series([], dtype: int64)\n",
      "\n",
      "NULL\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"NAN\")\n",
    "nan_counts = data.isna().sum()\n",
    "print(nan_counts[nan_counts > 0])\n",
    "\n",
    "print(\"\\nNULL\")\n",
    "null_counts = data.isnull().sum()\n",
    "print(null_counts[null_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int8   \n",
      " 1   Glucose                   768 non-null    int8   \n",
      " 2   BloodPressure             768 non-null    int8   \n",
      " 3   SkinThickness             768 non-null    int8   \n",
      " 4   Insulin                   768 non-null    int8   \n",
      " 5   BMI                       768 non-null    float32\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float32\n",
      " 7   Age                       768 non-null    int8   \n",
      " 8   Outcome                   768 non-null    int8   \n",
      "dtypes: float32(2), int8(7)\n",
      "memory usage: 11.4 KB\n"
     ]
    }
   ],
   "source": [
    "for col in data.select_dtypes(include=['int64']).columns:\n",
    "    data[col]=data[col].astype(np.int8)\n",
    "for col in data.select_dtypes(include=['float64']).columns:\n",
    "    data[col]=data[col].astype(np.float32)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def scaled_data(data):\n",
    "    data_copy = data.copy()\n",
    "    scaler = StandardScaler()\n",
    "    data_copy[data.columns] = scaler.fit_transform(data_copy[data.columns]) \n",
    "    return data_copy\n",
    "Sdata= scaled_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Sdata.iloc[:,:-1]\n",
    "y=data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    500\n",
       "1    268\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling\n",
    "- Reduces the majority class by removing samples to balance class distribution.\n",
    "- Can discard potentially useful information but is efficient for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Undersampling\n",
    "- Randomly removes samples from the majority class until a desired balance is achieved. \n",
    "- Simple but can discard potentially useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    213\n",
       "1    213\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomek Links\n",
    "- Identifies and removes majority class samples that form Tomek links (pairs of closest instances from different classes). \n",
    "- Helps clean decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    354\n",
       "1    213\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "# Create a TomekLinks undersampler\n",
    "tl = TomekLinks(sampling_strategy='auto')\n",
    "X_resampled, y_resampled = tl.fit_resample(X_train, y_train)\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NearMiss\n",
    "- Selects samples from the majority class based on distances to minority class instances. \n",
    "- Helps retain most informative majority samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    213\n",
       "1    213\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# NearMiss-1: Selects majority samples whose average distance to 3 closest minority samples is smallest\n",
    "nm1 = NearMiss(version=1, n_neighbors=3, sampling_strategy='auto')\n",
    "X_resampled, y_resampled = nm1.fit_resample(X_train, y_train)\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling\n",
    "- Increases the minority class by duplicating or creating synthetic samples. \n",
    "- Preserves all majority information but may lead to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE (Synthetic Minority Oversampling Technique)\n",
    "- Creates synthetic minority samples by interpolating between existing minority instances. \n",
    "- Helps address imbalance without simple duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "1    401\n",
       "0    401\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create a SMOTE oversampler\n",
    "smote = SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADASYN (Adaptive Synthetic Sampling)\n",
    "- Similar to SMOTE but generates more synthetic samples for minority instances that are harder to learn. \n",
    "- Focuses on difficult boundary regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    401\n",
       "1    392\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Create an ADASYN oversampler\n",
    "adasyn = ADASYN(sampling_strategy='auto', n_neighbors=5, random_state=42)\n",
    "\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X_train, y_train)\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borderline-SMOTE\n",
    "- Focuses on minority samples near the decision boundary to create synthetic samples in harder-to-learn regions. \n",
    "- More targeted than standard SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "1    401\n",
       "0    401\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# Create a Borderline-SMOTE oversampler\n",
    "b_smote = BorderlineSMOTE(sampling_strategy='auto', k_neighbors=5, random_state=42)\n",
    "X_resampled, y_resampled = b_smote.fit_resample(X_train, y_train)\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination\n",
    "Apply both oversampling and undersampling sequentially to balance classes while cleaning noisy samples and decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTETomek\n",
    "- First applies SMOTE oversampling, then cleans the resulting data using Tomek links. \n",
    "- Provides balanced data with cleaner boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "1    378\n",
       "0    378\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Create a SMOTE+Tomek Links combined resampler\n",
    "smote_tomek = SMOTETomek(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTEENN\n",
    "- Combines SMOTE oversampling with Edited Nearest Neighbors cleaning. \n",
    "- More aggressive cleaning than SMOTETomek, often produces better boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "1    250\n",
       "0    191\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Create a SMOTE+ENN combined resampler\n",
    "smote_enn = SMOTEENN(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "- Cross-validation involves partitioning data into subsets, training models on some subsets, and validating on others. \n",
    "- This helps assess how well a model generalizes to independent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr=X_train.values\n",
    "y_train_arr=y_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified K-Fold Cross-Validation\n",
    "- Maintains the same class distribution in each fold as in the complete dataset. \n",
    "- Essential for imbalanced classification evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy: 0.7411 ± 0.0237\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create stratified k-fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# Initialize scores list\n",
    "scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_idx, val_idx in skf.split(X_train_arr, y_train_arr):\n",
    "    # Split data for this fold\n",
    "    X_fold_train, X_fold_val = X_train_arr[train_idx], X_train_arr[val_idx]\n",
    "    y_fold_train, y_fold_val = y_train_arr[train_idx], y_train_arr[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "    model.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Evaluate and store score\n",
    "    score = model.score(X_fold_val, y_fold_val)\n",
    "    scores.append(score)\n",
    "\n",
    "# Calculate average performance\n",
    "mean_score = np.mean(scores)\n",
    "std_score = np.std(scores)\n",
    "print(f\"Cross-validation accuracy: {mean_score:.4f} ± {std_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TimeSeriesSplit\n",
    "- Respects temporal order in time series data by using past observations for training and future observations for validation. \n",
    "- Critical for time-dependent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series CV accuracy: 0.7353 ± 0.0206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "# Create time series cross-validator\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize scores list\n",
    "scores = []\n",
    "\n",
    "# Perform time series cross-validation\n",
    "for train_idx, val_idx in tscv.split(X_train_arr):\n",
    "    # Split data for this fold\n",
    "    X_fold_train, X_fold_val = X_train_arr[train_idx], X_train_arr[val_idx]\n",
    "    y_fold_train, y_fold_val = y_train_arr[train_idx], y_train_arr[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Evaluate and store score\n",
    "    score = model.score(X_fold_val, y_fold_val)\n",
    "    scores.append(score)\n",
    "\n",
    "# Calculate average performance\n",
    "mean_score = np.mean(scores)\n",
    "std_score = np.std(scores)\n",
    "print(f\"Time series CV accuracy: {mean_score:.4f} ± {std_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
